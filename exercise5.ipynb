{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bài 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dựa trên bộ dữ liệu tự thu thập từ các trang báo mạng Tiếng Việt (5 lớp/ mỗi lớp 10 mẩu tin), hãy thực hiện các yêu cầu sau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trang báo lựa chọn sẽ cào là 24h.com.vn \n",
    "\n",
    "Chia ra 5 label như sau:\n",
    "- Giao Thông : https://www.24h.com.vn/tai-nan-giao-thong-c408.html\n",
    "- Chính trị - Xã hội : https://www.24h.com.vn/chinh-tri-xa-hoi-c981.html\n",
    "- Kinh doanh : https://www.24h.com.vn/kinh-doanh-c161.html\n",
    "- Giải trí : https://www.24h.com.vn/giai-tri-c731.html\n",
    "- Thể thao : https://www.24h.com.vn/bong-da-c48.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install undetected-chromedriver\n",
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_giaothong = 'https://www.24h.com.vn/tai-nan-giao-thong-c408.html'\n",
    "web_chinhtri = 'https://www.24h.com.vn/chinh-tri-xa-hoi-c981.html'\n",
    "web_thoitiet = 'https://www.24h.com.vn/du-bao-thoi-tiet-c568.html'\n",
    "web_thethao = 'https://www.24h.com.vn/the-thao-c101.html'\n",
    "web_giaitri = 'https://www.24h.com.vn/giai-tri-c731.html'\n",
    "\n",
    "all_webs = [web_giaothong, web_chinhtri,web_thoitiet, web_thethao, web_giaitri]\n",
    "labels = ['giaothong', 'chinhtri', 'kinhdoanh', 'thethao', 'giaitri']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import undetected_chromedriver as uc \n",
    "from selenium.webdriver.common.by import By \n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"--start-maximized\")\n",
    "driver = uc.Chrome(options=options)\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "wait = WebDriverWait(driver,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [03:48<00:00, 11.44s/it]\n",
      "100%|██████████| 20/20 [02:07<00:00,  6.35s/it]\n",
      "100%|██████████| 22/22 [02:23<00:00,  6.52s/it]\n",
      "100%|██████████| 12/12 [00:52<00:00,  4.39s/it]\n",
      "100%|██████████| 14/14 [00:56<00:00,  4.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Con gái rapper Thái VG gây sốt khi lên sóng tr...</td>\n",
       "      <td>[Chỉ xuất hiện vỏn vẹn 6 giây trong trailer ch...</td>\n",
       "      <td>giaitri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Tin tức 24h qua: Tòa bác đơn xin hoãn chấp hàn...</td>\n",
       "      <td>[Tòa bác đơn xin hoãn chấp hành án trong vụ \"E...</td>\n",
       "      <td>kinhdoanh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Quán quân Rap Việt mùa 3: \"Người miền núi chất...</td>\n",
       "      <td>[Đêm chung kết Công bố và Trao giải Rap Việt m...</td>\n",
       "      <td>giaitri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Dàn mỹ nhân \"Cổng mặt trời\" hội ngộ: Nhan sắc ...</td>\n",
       "      <td>[Cổng mặt trời là bộ phim truyền hình gắn liền...</td>\n",
       "      <td>giaitri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Sau khi bị khởi tố, nguyên Giám đốc Sở GD-ĐT G...</td>\n",
       "      <td>[Ngày 8-9, UBKT Tỉnh ủy Gia Lai cho biết đã đề...</td>\n",
       "      <td>chinhtri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Quảng Bình: Hơn 1.600 vụ ly hôn trong 8 tháng</td>\n",
       "      <td>[Ngày 9-9, ông Nguyễn Hữu Tuyến, Chánh án TAND...</td>\n",
       "      <td>giaothong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "76  Con gái rapper Thái VG gây sốt khi lên sóng tr...   \n",
       "53  Tin tức 24h qua: Tòa bác đơn xin hoãn chấp hàn...   \n",
       "77  Quán quân Rap Việt mùa 3: \"Người miền núi chất...   \n",
       "81  Dàn mỹ nhân \"Cổng mặt trời\" hội ngộ: Nhan sắc ...   \n",
       "31  Sau khi bị khởi tố, nguyên Giám đốc Sở GD-ĐT G...   \n",
       "14      Quảng Bình: Hơn 1.600 vụ ly hôn trong 8 tháng   \n",
       "\n",
       "                                              content      label  \n",
       "76  [Chỉ xuất hiện vỏn vẹn 6 giây trong trailer ch...    giaitri  \n",
       "53  [Tòa bác đơn xin hoãn chấp hành án trong vụ \"E...  kinhdoanh  \n",
       "77  [Đêm chung kết Công bố và Trao giải Rap Việt m...    giaitri  \n",
       "81  [Cổng mặt trời là bộ phim truyền hình gắn liền...    giaitri  \n",
       "31  [Ngày 8-9, UBKT Tỉnh ủy Gia Lai cho biết đã đề...   chinhtri  \n",
       "14  [Ngày 9-9, ông Nguyễn Hữu Tuyến, Chánh án TAND...  giaothong  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_content(link):\n",
    "    driver.get(link)\n",
    "    content= wait.until(EC.presence_of_all_elements_located((By.XPATH,'//article/p')))\n",
    "    title=driver.title.replace(u'\\xa0', u' ')\n",
    "    content = [p.text for p in content if p.text != '']\n",
    "    return title,content\n",
    "\n",
    "\n",
    "def get_all_content_label(link_labels,label):\n",
    "    driver.get(link_labels)\n",
    "    all_links = wait.until(EC.presence_of_all_elements_located((By.XPATH,'//header/*[@class=\"cate-24h-foot-home-latest-list__name\"]/a')))\n",
    "    while len(all_links) < 10:\n",
    "        wait.until(EC.presence_of_element_located((By.XPATH,'//div/p/a'))).click()\n",
    "        sleep(2)\n",
    "        all_links = wait.until(EC.presence_of_all_elements_located((By.XPATH,'//header/*[@class=\"cate-24h-foot-home-latest-list__name\"]/a')))\n",
    "\n",
    "    all_links = [link.get_attribute('href') for link in all_links]\n",
    "    \n",
    "    titles = []\n",
    "    contents = []\n",
    "    labels = []\n",
    "    for link in tqdm(all_links):\n",
    "        title, content = get_content(link)\n",
    "        titles.append(title)\n",
    "        contents.append(content)\n",
    "        labels.append(label)\n",
    "\n",
    "    return titles, contents, labels    \n",
    "\n",
    "big_tit= []\n",
    "big_cont=[]\n",
    "big_labels=[]\n",
    "df = pd.DataFrame(columns=['title','content','label'])\n",
    "for links,label in zip(all_webs,labels):\n",
    "    titles, contents, all_labels = get_all_content_label(links,label)\n",
    "    big_tit += titles\n",
    "    big_cont += contents\n",
    "    big_labels += all_labels\n",
    "\n",
    "df = pd.DataFrame({'title':big_tit,'content':big_cont,'label':big_labels})\n",
    "df.to_csv('data.csv',index=False)\n",
    "df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Tiền xử lí dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from underthesea import sent_tokenize,word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from textblob import Word\n",
    "from nltk.util import ngrams\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Clip: Thấy con chó lao thẳng vào xe máy SH, tà...</td>\n",
       "      <td>['Hình ảnh vụ tai nạn được chia sẻ trên nhóm F...</td>\n",
       "      <td>giaothong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Đau đầu với 650 chiếc xe máy \"bỏ quên\" tại nhà...</td>\n",
       "      <td>['Hàng trăm xe máy để tại tầng 3-5 của Nhà để ...</td>\n",
       "      <td>giaothong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ngông nghênh đi lên Vành đai 2 trên cao, cả lo...</td>\n",
       "      <td>['Tuyến Vành đai 2 trên, đoạn lối xuống đường ...</td>\n",
       "      <td>giaothong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Xe tải bị lật nghiêng sau tai nạn trên cao tốc...</td>\n",
       "      <td>['Hiện trường vụ tai nạn.', 'Chiều 8/9, đại di...</td>\n",
       "      <td>giaothong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clip: Phóng xe máy như bay lao vào đầu ô tô, đ...</td>\n",
       "      <td>['Hình ảnh vụ tai nạn hôm 5/9 được chia sẻ trê...</td>\n",
       "      <td>giaothong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Clip: Thấy con chó lao thẳng vào xe máy SH, tà...   \n",
       "1  Đau đầu với 650 chiếc xe máy \"bỏ quên\" tại nhà...   \n",
       "2  Ngông nghênh đi lên Vành đai 2 trên cao, cả lo...   \n",
       "3  Xe tải bị lật nghiêng sau tai nạn trên cao tốc...   \n",
       "4  Clip: Phóng xe máy như bay lao vào đầu ô tô, đ...   \n",
       "\n",
       "                                             content      label  \n",
       "0  ['Hình ảnh vụ tai nạn được chia sẻ trên nhóm F...  giaothong  \n",
       "1  ['Hàng trăm xe máy để tại tầng 3-5 của Nhà để ...  giaothong  \n",
       "2  ['Tuyến Vành đai 2 trên, đoạn lối xuống đường ...  giaothong  \n",
       "3  ['Hiện trường vụ tai nạn.', 'Chiều 8/9, đại di...  giaothong  \n",
       "4  ['Hình ảnh vụ tai nạn hôm 5/9 được chia sẻ trê...  giaothong  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv', encoding='utf-8')\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hình ảnh vụ tai nạn được chia sẻ trên nhóm facebook về giao thông cho thấy sau tai nạn tài xế xe máy sh có thể ngồi dậy và may mắn không va chạm với phương tiện nào khác trong khi đó con chó gây tai nạn bỏ chạy từ vụ tai nạn trên trao đổi với pv về quy định xử lý hành vi thả rông động vật gây tai nạn giao thông luật sư lê văn kiên trưởng văn phòng luật sư ánh sáng công lý cho biết việc xử lý hành vi thả rông vật nuôi được quy định tại nghị định nđ cp nghị định quy định xử phạt vi phạm hành chính trong lĩnh vực an ninh trật tự an toàn xã hội phòng chống tệ nạn xã hội phòng cháy chữa cháy cứu nạn cứu hộ phòng chống bạo lực gia đình theo nghị định nđ cp quy định chủ vật nuôi sẽ bị phạt tiền từ đồng đến đồng về hành vi để động vật nuôi gây thương tích hoặc gây thiệt hại tài sản cho tổ chức cá nhân khác nhưng không bị truy cứu trách nhiệm hình sự với hành vi để vật nuôi xâm lấn lòng đường vỉa hè vườn hoa sân chơi đô thị nơi sinh hoạt chung trong khu dân cư khu đô thị chủ vật nuôi sẽ bị xử phạt từ đồng đến đồng theo nghị định nđ cp trong trường hợp súc vật thả rông gây ra vụ tai nạn dẫn tới thiệt hại về sức khỏe và tài sản cho các nạn nhân thì chủ sở hữu vật nuôi còn phải bồi thường thiệt hại do súc vật gây ra theo điều bộ luật dân sự năm cụ thể luật quy định người chiếm hữu sử dụng súc vật phải bồi thường thiệt hại trong thời gian chiếm hữu sử dụng súc vật trừ trường hợp có thỏa thuận khác luật sư kiên nói nguồn URL'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def processcing_text(text):\n",
    "    tweet = text\n",
    "    #lower\n",
    "    tweet = tweet.lower()\n",
    "    #convert any url link to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))', 'URL', tweet)\n",
    "    #convert any @Username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+', 'AT_USER', tweet)\n",
    "\n",
    "    #Remove not alphanumeric symbols white spaces\n",
    "    tweet = re.sub(r'[^\\w]',' ', tweet)\n",
    "    #Removes # hashtag in front of a word\n",
    "    tweet = re.sub(r'#([\\w]+)', r'\\1', tweet)\n",
    "    tweet = re.sub(r'#([^\\s]+)',r'\\1',tweet)\n",
    "    #remove :( or :)\n",
    "    tweet = tweet.replace(':)','')\n",
    "    tweet = tweet.replace(':(','')\n",
    "    #remove numbers\n",
    "    tweet = ''.join([i for i in tweet if not i.isdigit()])\n",
    "    #remove multiple exclamation\n",
    "    tweet = re.sub(r'(!)\\1+', ' ', tweet)\n",
    "    #remove multiple question marks\n",
    "    tweet = re.sub(r'(\\?)\\1+','', tweet)\n",
    "    #remove multistop\n",
    "    tweet = re.sub(r'(\\.)\\1+','', tweet)\n",
    "    #Remove additional whitespace\n",
    "    tweet = re.sub(r'[\\s]+',' ', tweet)\n",
    "    tweet = re.sub(r'[\\n]+',' ', tweet)\n",
    "    #lemma \n",
    "    # tweet = \" \".join([Word(word).lemmatize() for word in tweet.split()])\n",
    "    #stemmer\n",
    "    # st=  PorterStemmer()\n",
    "    # tweet = \" \".join([st.stem(word) for word in tweet.split()])\n",
    "    #remove emoteicon from text\n",
    "    # tweet = re.sub('')\n",
    "    row = tweet\n",
    "    return row\n",
    "\n",
    "df['content']=df['content'].apply(processcing_text)\n",
    "df.head(1)['content'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Tách từ (Tokenize) sử dụng thư viện pyvi hay underthesea\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hình_ảnh vụ tai_nạn được chia_sẻ trên nhóm facebook về giao_thông cho thấy sau tai_nạn tài_xế xe_máy sh có_thể ngồi dậy và may_mắn không va_chạm với phương_tiện nào khác trong khi đó con chó gây tai_nạn bỏ chạy từ vụ tai_nạn trên trao_đổi với pv về quy_định xử_lý hành_vi thả rông động_vật gây tai_nạn giao_thông luật_sư lê_văn_kiên_trưởng văn_phòng luật_sư ánh_sáng công_lý cho biết việc xử_lý hành_vi thả rông vật_nuôi được quy_định tại nghị_định nđ cp nghị_định quy_định xử_phạt vi_phạm hành_chính trong lĩnh_vực an_ninh trật_tự an_toàn xã_hội phòng_chống tệ_nạn xã_hội phòng cháy chữa_cháy cứu nạn cứu_hộ phòng_chống bạo_lực gia_đình theo nghị_định nđ cp quy_định chủ vật_nuôi sẽ bị phạt tiền từ đồng đến đồng về hành_vi để động_vật_nuôi gây thương_tích hoặc gây thiệt_hại tài_sản cho tổ_chức cá_nhân khác nhưng không bị truy_cứu trách_nhiệm hình_sự với hành_vi để vật_nuôi xâm_lấn lòng_đường vỉa_hè vườn hoa sân_chơi đô_thị nơi sinh_hoạt chung trong khu dân_cư khu đô_thị chủ vật_nuôi sẽ bị xử_phạt từ đồng đến đồng theo nghị_định nđ cp trong trường_hợp súc_vật thả rông gây ra vụ tai_nạn dẫn tới thiệt_hại về sức_khỏe và tài_sản cho các nạn_nhân thì chủ_sở_hữu vật_nuôi còn phải bồi_thường thiệt_hại do súc_vật gây ra theo điều bộ_luật dân_sự năm cụ_thể luật quy_định người chiếm_hữu sử_dụng súc_vật phải bồi_thường thiệt_hại trong thời_gian chiếm_hữu sử_dụng súc_vật trừ trường_hợp có thỏa_thuận khác luật_sư kiên_nói nguồn URL'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from underthesea import word_tokenize\n",
    "\n",
    "\n",
    "def toke(text):\n",
    "    t=word_tokenize(text, format='text')\n",
    "    # t=word_tokenize(t)\n",
    "    return t\n",
    "\n",
    "df['content']=df['content'].apply(toke)\n",
    "\n",
    "df['content'].head(1).values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Trích xuất đặc trưng TF-IDF bằng thư viện sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 3737), (88,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "corpus = df['content'].values\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X = tfidf_vectorizer.fit_transform(corpus)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['label'].values)\n",
    "X.toarray().shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoder:\n",
    "- Chính trị : 0\n",
    "- Giải trí : 1\n",
    "- Giao thông : 2\n",
    "- Kinh doanh : 3\n",
    "- Thể thao : 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['chinhtri', 'giaitri', 'giaothong', 'kinhdoanh', 'thethao'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder.inverse_transform([0,1,2,3,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Đánh giá bộ dữ liệu với giải thuật KNN bằng phương pháp 5-Fold (k-fold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Accuracy: 0.661437908496732\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2)  \n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "accuracies = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    y_train, y_val = y[train_index], y[val_index]\n",
    "\n",
    "    knn.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = knn.predict(X_val)\n",
    "\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "average_accuracy = np.mean(accuracies)\n",
    "print(f'Average Accuracy: {average_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Huấn luyện dữ liệu cho bài toán phân loại văn bản với tỷ lệ dữ liệu 8:2 (8 phần train, 2 phần test) sử dụng đặc trưng TF-IDF và 2 giải thuật bayes và SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train.toarray() , y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "svm_predictions = svm_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Tính độ đo F1 score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of Naive Bayes:  0.7222222222222222\n",
      "F1 score of SVM:  0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,f1_score,confusion_matrix \n",
    "\n",
    "print('F1 score of Naive Bayes: ', f1_score(y_test, nb_predictions, average='micro'))\n",
    "print('F1 score of SVM: ', f1_score(y_test, svm_predictions, average='micro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Tính độ đo Accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of Naive Bayes:  0.7222222222222222\n",
      "Accuracy score of SVM:  0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy score of Naive Bayes: ', accuracy_score(y_test, nb_predictions))\n",
    "print('Accuracy score of SVM: ', accuracy_score(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Tính độ đo Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix of Naive Bayes: \n",
      " [[2 0 1 0 0]\n",
      " [0 4 0 0 1]\n",
      " [1 1 3 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 4]]\n",
      "Confusion matrix of SVM: \n",
      " [[3 0 0 0 0]\n",
      " [1 3 0 0 1]\n",
      " [3 0 2 0 0]\n",
      " [0 0 0 1 0]\n",
      " [1 0 2 0 1]]\n"
     ]
    }
   ],
   "source": [
    "print('Confusion matrix of Naive Bayes: \\n', confusion_matrix(y_test, nb_predictions)) \n",
    "print('Confusion matrix of SVM: \\n', confusion_matrix(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. So sánh kết quả các độ đo 6,7,8 với 2 giải thuật học máy ở trên\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So sánh giải thuật SVM và Bayes thì Bayes cho kết quả tốt, vượt trội hơn SVM \n",
    "\n",
    "Vì lí do dữ liệu vẫn còn khá ít và các label phân chia nhau chưa rõ ràng nên điểm số chưa cao \n",
    "\n",
    "Cần khắc phục bằng cách tăng dữ liệu và phân chia rõ ràng hơn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10.Lưu model với giải thuật đạt kết quả tốt nhất\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tfidf_vectorizer.pkl']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(nb_classifier, 'nb_classifier.pkl')\n",
    "dump(tfidf_vectorizer, 'tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_nb_classifier = load('nb_classifier.pkl')\n",
    "loaded_tfidf_vectorizer = load('tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'giaothong'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_text_to_label(text):\n",
    "    text = processcing_text(text)\n",
    "    text = toke(text)\n",
    "    text = loaded_tfidf_vectorizer.transform([text]).toarray()\n",
    "    label = loaded_nb_classifier.predict(text)\n",
    "    label_name = label_encoder.inverse_transform(label)\n",
    "    return label_name[0]\n",
    "\n",
    "text_test='Một vụ tai nạn giao thông thảm khốc xảy ra ở tân bình'\n",
    "predict_text_to_label(text_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bài 2: Cho ví dụ sử dụng HashVectorizer như sau:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "corpus = [\n",
    " ' Hôm_nay tôi đi_học',\n",
    " ' Hôm_nay tôi đi_học ở trường',\n",
    " ' Hôm_nay tôi nghỉ ở nhà',\n",
    " ' Hôm_nay tôi có đi_học không?',\n",
    "]\n",
    "vectorizer = HashingVectorizer(n_features=2**4)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "corpus = [\n",
    " ' Hôm_nay tôi đi_học',\n",
    " ' Hôm_nay tôi đi_học ở trường',\n",
    " ' Hôm_nay tôi nghỉ ở nhà',\n",
    " ' Hôm_nay tôi có đi_học không?',\n",
    "]\n",
    "vectorizer = HashingVectorizer(n_features=2**5)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm HashingVectorizer sẽ tương tự tfidf nhưng số lượng feature thay vì đưa vô sẽ dễ ra một vecto thưa(Spare vector) thì sẽ được đưa vào một mảng băm với số lượng feature là tùy chỉnh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài 3: Sử dụng HashVectorizer thay cho đặc trưng TF-IDF ở bài 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((88, 16384), (88,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hash_vec = HashingVectorizer(n_features=2**14)\n",
    "corpus = df['content'].values\n",
    "X = hash_vec.fit_transform(corpus)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['label'].values)\n",
    "X.toarray().shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of Naive Bayes:  0.7222222222222222\n",
      "F1 score of SVM:  0.6666666666666666\n",
      "Accuracy score of Naive Bayes:  0.7222222222222222\n",
      "Accuracy score of SVM:  0.6666666666666666\n",
      "Confusion matrix of Naive Bayes: \n",
      " [[2 0 1 0 0]\n",
      " [0 4 0 0 1]\n",
      " [1 1 3 0 0]\n",
      " [0 0 1 0 0]\n",
      " [0 0 0 0 4]]\n",
      "Confusion matrix of SVM: \n",
      " [[3 0 0 0 0]\n",
      " [0 4 0 0 1]\n",
      " [3 0 2 0 0]\n",
      " [0 0 0 1 0]\n",
      " [0 1 1 0 2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB,GaussianNB\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train.toarray() , y_train)\n",
    "nb_predictions = nb_classifier.predict(X_test.toarray())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "svm_classifier.fit(X_train, y_train)\n",
    "\n",
    "svm_predictions = svm_classifier.predict(X_test)\n",
    "\n",
    "\n",
    "print('F1 score of Naive Bayes: ', f1_score(y_test, nb_predictions, average='micro'))\n",
    "print('F1 score of SVM: ', f1_score(y_test, svm_predictions, average='micro'))\n",
    "print('Accuracy score of Naive Bayes: ', accuracy_score(y_test, nb_predictions))\n",
    "print('Accuracy score of SVM: ', accuracy_score(y_test, svm_predictions))\n",
    "print('Confusion matrix of Naive Bayes: \\n', confusion_matrix(y_test, nb_predictions)) \n",
    "print('Confusion matrix of SVM: \\n', confusion_matrix(y_test, svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
